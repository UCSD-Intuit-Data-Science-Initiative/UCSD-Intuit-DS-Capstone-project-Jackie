{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bd8106",
   "metadata": {},
   "source": [
    "## Modeling (Baseline Model: Seasonal Naive Forecast)\n",
    "the forecast for any given day is the value from the same day in the previous week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cf0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split data chronologically\n",
    "train = df[df.index < \"2025-03-01\"]\n",
    "test = df[df.index >= \"2025-03-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the baseline forecast\n",
    "test_dates = test.index\n",
    "# We need the last 7 days of the training set to start the forecast\n",
    "history = train[\"Incoming Calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a610a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions with Seasonal Naive (Weekly) - handle missing dates\n",
    "predictions = []\n",
    "actual_test_dates = []\n",
    "\n",
    "for date in test_dates:\n",
    "    # Find the date from 7 days ago\n",
    "    last_week_date = date - pd.Timedelta(days=7)\n",
    "\n",
    "    # Check if the date exists in the training data\n",
    "    if last_week_date in history.index:\n",
    "        prediction = history.loc[last_week_date]\n",
    "        predictions.append(prediction)\n",
    "        actual_test_dates.append(date)\n",
    "\n",
    "# Create a series with the predictions for evaluation\n",
    "predictions_series = pd.Series(predictions, index=actual_test_dates)\n",
    "actual_values = test.loc[actual_test_dates, \"Incoming Calls\"]\n",
    "\n",
    "print(f\"Number of predictions made: {len(predictions)}\")\n",
    "print(\"Predictions (first 10):\")\n",
    "print(predictions_series.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evaluate the baseline model\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(actual_values, predictions_series)\n",
    "rmse = np.sqrt(mean_squared_error(actual_values, predictions_series))\n",
    "mape = mean_absolute_percentage_error(actual_values, predictions_series)\n",
    "\n",
    "print(\"Seasonal Naive (Weekly) Baseline Model - Evaluation Metrics\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Mean Absolute Error (MAE):           {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):      {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f} ({mape*100:.2f}%)\")\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualize predictions vs actual values\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot actual test values\n",
    "plt.plot(actual_test_dates, actual_values, \"o-\", label=\"Actual\", linewidth=2, markersize=5)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(actual_test_dates, predictions_series, \"s--\", label=\"Seasonal Naive (Weekly)\", linewidth=2, markersize=5, alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Incoming Calls\", fontsize=12)\n",
    "plt.title(\"Seasonal Naive (Weekly) Baseline Model - Predictions vs Actual\", fontsize=14, fontweight=\"bold\")\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPrediction accuracy comparison:\")\n",
    "print(f\"Min calls: {actual_values.min():.0f}, Max calls: {actual_values.max():.0f}\")\n",
    "print(f\"Mean actual: {actual_values.mean():.2f}, Mean predicted: {predictions_series.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c93a3",
   "metadata": {},
   "source": [
    "## Advanced Model: SARIMA (Seasonal AutoRegressive Integrated Moving Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install statsmodels if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"statsmodels\"])\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SARIMA model with simple, proven parameters\n",
    "# SARIMA(1,1,1)(1,1,1,7) - common good baseline for weekly seasonal data\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Simple SARIMA parameters\n",
    "order = (1, 1, 1)  # (p, d, q)\n",
    "seasonal_order = (1, 1, 1, 7)  # (P, D, Q, m) - m=7 for weekly seasonality\n",
    "\n",
    "print(f\"Training SARIMA{order}x{seasonal_order} model...\")\n",
    "print(\"Parameters: p=1, d=1, q=1 (non-seasonal), P=1, D=1, Q=1, m=7 (seasonal)\\n\")\n",
    "\n",
    "sarima_model = SARIMAX(\n",
    "    train[\"Incoming Calls\"],\n",
    "    order=order,\n",
    "    seasonal_order=seasonal_order,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False,\n",
    ")\n",
    "\n",
    "sarima_results = sarima_model.fit(disp=False)\n",
    "print(\"SARIMA Model trained successfully!\")\n",
    "\n",
    "# Make predictions on test set\n",
    "sarima_predictions = sarima_results.get_forecast(steps=len(test))\n",
    "sarima_forecast = sarima_predictions.predicted_mean\n",
    "\n",
    "# Evaluate SARIMA model\n",
    "sarima_mae = mean_absolute_error(test[\"Incoming Calls\"], sarima_forecast)\n",
    "sarima_rmse = np.sqrt(mean_squared_error(test[\"Incoming Calls\"], sarima_forecast))\n",
    "sarima_mape = mean_absolute_percentage_error(test[\"Incoming Calls\"], sarima_forecast)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SARIMA Model - Evaluation Metrics\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean Absolute Error (MAE):           {sarima_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):      {sarima_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {sarima_mape:.4f} ({sarima_mape*100:.2f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(test.index, test[\"Incoming Calls\"], \"o-\", label=\"Actual\", linewidth=2, markersize=5)\n",
    "plt.plot(test.index, sarima_forecast, \"s--\", label=\"SARIMA Predictions\", linewidth=2, markersize=5, alpha=0.7)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Incoming Calls\", fontsize=12)\n",
    "plt.title(\"SARIMA Model - Predictions vs Actual\", fontsize=14, fontweight=\"bold\")\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a8084",
   "metadata": {},
   "source": [
    "## Advanced Model: Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e77ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install prophet if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"prophet\"])\n",
    "    from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff25766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet\n",
    "# Prophet requires columns 'ds' (datestamp) and 'y' (value)\n",
    "prophet_train = train.reset_index()\n",
    "prophet_train = prophet_train.rename(columns={\"Date\": \"ds\", \"Incoming Calls\": \"y\"})\n",
    "\n",
    "# Initialize and train the model\n",
    "prophet_model = Prophet(\n",
    "    seasonality_mode=\"multiplicative\",  # Good for data with trends\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    ")\n",
    "prophet_model.fit(prophet_train)\n",
    "\n",
    "# Create future dataframe for predictions\n",
    "future = prophet_model.make_future_dataframe(periods=len(test))\n",
    "forecast = prophet_model.predict(future)\n",
    "\n",
    "# Extract predictions for the test set period\n",
    "prophet_forecast = forecast[forecast[\"ds\"].isin(test.index)]\n",
    "\n",
    "print(\"Prophet model trained and forecast generated.\")\n",
    "print(f\"Forecast length: {len(prophet_forecast)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Prophet model\n",
    "prophet_mae = mean_absolute_error(test[\"Incoming Calls\"], prophet_forecast[\"yhat\"])\n",
    "prophet_rmse = np.sqrt(mean_squared_error(test[\"Incoming Calls\"], prophet_forecast[\"yhat\"]))\n",
    "prophet_mape = mean_absolute_percentage_error(test[\"Incoming Calls\"], prophet_forecast[\"yhat\"])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Prophet Model - Evaluation Metrics\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean Absolute Error (MAE):           {prophet_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):      {prophet_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {prophet_mape:.4f} ({prophet_mape*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Prophet forecast\n",
    "fig1 = prophet_model.plot(forecast)\n",
    "plt.title(\"Prophet Forecast - Full Data View\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Incoming Calls\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Plot Prophet components\n",
    "fig2 = prophet_model.plot_components(forecast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three models\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Seasonal Naive MAE\": [mae],\n",
    "        \"Seasonal Naive RMSE\": [rmse],\n",
    "        \"Seasonal Naive MAPE\": [mape * 100],\n",
    "        \"SARIMA MAE\": [sarima_mae],\n",
    "        \"SARIMA RMSE\": [sarima_rmse],\n",
    "        \"SARIMA MAPE\": [sarima_mape * 100],\n",
    "        \"Prophet MAE\": [prophet_mae],\n",
    "        \"Prophet RMSE\": [prophet_rmse],\n",
    "        \"Prophet MAPE\": [prophet_mape * 100],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON - Baseline vs SARIMA vs Prophet\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.T)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ba2d4",
   "metadata": {},
   "source": [
    "## Time Series Cross-Validation for SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e42e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross-Validation for SARIMA\n",
    "# This uses a rolling window approach: train on increasing data, test on next period\n",
    "\n",
    "\n",
    "def time_series_cv_sarima(data, n_splits=5, test_size=7):\n",
    "    \"\"\"\n",
    "    Perform time series cross-validation for SARIMA model\n",
    "\n",
    "    Args:\n",
    "        data: Time series data (pandas Series)\n",
    "        n_splits: Number of cross-validation splits\n",
    "        test_size: Number of periods to use for testing in each split\n",
    "\n",
    "    Returns:\n",
    "        List of MAE scores for each fold\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate split points\n",
    "    total_length = len(data)\n",
    "    min_train_size = total_length - n_splits * test_size\n",
    "\n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "\n",
    "    print(f\"Performing {n_splits}-fold time series cross-validation...\")\n",
    "    print(f\"Test size per fold: {test_size} days\")\n",
    "    print(f\"Minimum training size: {min_train_size} days\\n\")\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        # Calculate train and test indices\n",
    "        test_end = total_length - i * test_size\n",
    "        test_start = test_end - test_size\n",
    "        train_end = test_start\n",
    "\n",
    "        # Split data\n",
    "        cv_train = data.iloc[:train_end]\n",
    "        cv_test = data.iloc[test_start:test_end]\n",
    "\n",
    "        print(f\"Fold {i+1}/{n_splits}: Train size = {len(cv_train)}, Test size = {len(cv_test)}\")\n",
    "\n",
    "        try:\n",
    "            # Train SARIMA model\n",
    "            cv_model = SARIMAX(\n",
    "                cv_train,\n",
    "                order=(1, 1, 1),\n",
    "                seasonal_order=(1, 1, 1, 7),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False,\n",
    "            )\n",
    "            cv_results = cv_model.fit(disp=False)\n",
    "\n",
    "            # Make predictions\n",
    "            cv_forecast = cv_results.get_forecast(steps=len(cv_test))\n",
    "            cv_pred = cv_forecast.predicted_mean\n",
    "\n",
    "            # Calculate metrics\n",
    "            mae = mean_absolute_error(cv_test, cv_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(cv_test, cv_pred))\n",
    "            mape = mean_absolute_percentage_error(cv_test, cv_pred)\n",
    "\n",
    "            mae_scores.append(mae)\n",
    "            rmse_scores.append(rmse)\n",
    "            mape_scores.append(mape)\n",
    "\n",
    "            print(f\"  MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error in fold {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return mae_scores, rmse_scores, mape_scores\n",
    "\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cv_mae, cv_rmse, cv_mape = time_series_cv_sarima(train[\"Incoming Calls\"], n_splits=5, test_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cross-validation results\n",
    "if cv_mae:  # Check if we have results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TIME SERIES CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"Number of successful folds: {len(cv_mae)}\")\n",
    "    print(\"\\nMAE Scores by Fold:\")\n",
    "    for i, mae in enumerate(cv_mae, 1):\n",
    "        print(f\"  Fold {i}: {mae:.2f}\")\n",
    "\n",
    "    print(\"\\nCross-Validation Summary:\")\n",
    "    print(f\"  Mean MAE:  {np.mean(cv_mae):.2f} ± {np.std(cv_mae):.2f}\")\n",
    "    print(f\"  Mean RMSE: {np.mean(cv_rmse):.2f} ± {np.std(cv_rmse):.2f}\")\n",
    "    print(f\"  Mean MAPE: {np.mean(cv_mape):.4f} ± {np.std(cv_mape):.4f}\")\n",
    "\n",
    "    print(\"\\nComparison with Single Test:\")\n",
    "    print(f\"  Single Test MAE:  {sarima_mae:.2f}\")\n",
    "    print(f\"  CV Mean MAE:      {np.mean(cv_mae):.2f}\")\n",
    "    print(f\"  Difference:       {abs(sarima_mae - np.mean(cv_mae)):.2f}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"No successful cross-validation folds completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
